import numpy as np
image_size=416
# lowest_grid=13
# num_yolo_layers=3
device="cuda"
epochs=50000
batch_size=16
# lr=0.0000003
lr=2e-5

step_print_loss=1000
step_save=4000
step_evaluate=1000
# anchor_size_list=[[1,1]]
# anchor_size_list=[[0.36,0.42],[0.578,0.906],[1.265,1.281],[2.109,2.640],[5.375,4.984]]
anchor_size_list=[[0.156,0.203],[0.25,0.468],[0.515,0.359],[0.468,0.953],[0.968,0.703],[0.921, 1.859],[1.812, 1.406],[2.437, 3.093],[5.828, 5.093]]
anchor_size_list_split=[[[0.156,0.203],[0.25,0.468],[0.515,0.359]],[[0.468,0.953],[0.968,0.703],[0.921, 1.859]],[[1.812, 1.406],[2.437, 3.093],[5.828, 5.093]]]
l=[[10,13],  [16,30],  [33,23],  [30,61],  [62,45],  [59,119],  [116,90],  [156,198],  [373,326]]


# DEBUG
use_subset=False
subset_size=8
augment=False
shuffle=True
use_scheduler=False

# 48,58,77,(51,35,39)
# 360000mean loss for 1000 steps: lbox=0.06531417369842529,lobj=0.3080815374851227,lcls=0.05287227779626846,total loss=0.42626747488975525
# 486000mean loss for 1000 steps: lbox=0.03925161063671112,lobj=0.059154409915208817,lcls=0.04595803841948509,total loss=0.1443641483783722
#step=564000
# lr=[4e-06]adamw
# mean loss for 1000 steps: lbox=0.0655708909034729,lobj=0.1596800833940506,lcls=0.053628917783498764,total loss=0.2788794934749603
# step=2408000
# lr=[4e-06]adamw
# mean loss for 1000 steps: lbox=0.03433879092335701,lobj=0.1076355054974556,lcls=0.03297692909836769,total loss=0.17495110630989075
# step=2452000
# lr=[4e-06]
# mean loss for 1000 steps: lbox=0.03384266793727875,lobj=0.10505811870098114,lcls=0.03261638805270195,total loss=0.17151716351509094
# step=2533000
# lr=[3.9999999999999996e-05]
# mean loss for 1000 steps: lbox=0.033063992857933044,lobj=0.10398721694946289,lcls=0.03228474035859108,total loss=0.16933611035346985
# step=2564000
# lr=[3e-05]
# mean loss for 1000 steps: lbox=0.032914504408836365,lobj=0.1032094731926918,lcls=0.032362211495637894,total loss=0.16848617792129517
# GG_step=2548000
# lr=[2e-05]
# mean loss for 1000 steps: lbox=0.008325287140905857,lobj=0.006024657282978296,lcls=0.006436765659600496,total loss=0.020786695182323456